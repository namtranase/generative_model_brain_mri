{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pggan_huy_keras.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jM0quPXQ0Odx",
        "outputId": "5e41d9a8-bb0f-4a2e-b227-141a1ad6bb0f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVGuR52pU-qH"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Layer\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import AveragePooling2D\n",
        "from tensorflow.keras.layers import UpSampling2D\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Add\n",
        "from tensorflow.keras.layers import Reshape\n",
        "from tensorflow.keras.initializers import RandomNormal\n",
        "from tensorflow.keras.constraints import max_norm\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import backend\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGGMCTmD--fO"
      },
      "source": [
        "from numpy import asarray\n",
        "from numpy import zeros\n",
        "from numpy import ones\n",
        "from matplotlib import pyplot"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIwWvSFBhgMB"
      },
      "source": [
        "from skimage import io\n",
        "from PIL import Image\n",
        "import os \n",
        "import glob \n",
        "import numpy as np\n",
        "import cv2"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZ9_uwpcthSo"
      },
      "source": [
        "from numpy.random import randint,randn"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfLHtF1v7_Al"
      },
      "source": [
        "# use for fade newblock\n",
        "class FadeBlock(Add):\n",
        "  \"\"\"\n",
        "\n",
        "  \"\"\"\n",
        "\t# init with default value\n",
        "  def __init__(self, alpha=0.0, **kwargs):\n",
        "    super(FadeBlock, self).__init__(**kwargs)\n",
        "    self.alpha = backend.variable(alpha, name='ws_alpha')\n",
        " \n",
        "\t# output a weighted sum of inputs\n",
        "  def _merge_function(self, inputs):\n",
        "    assert (len(inputs) == 2)\n",
        "    # ((1-a) * input1) + (a * input2)\n",
        "    output = ((1.0 - self.alpha) * inputs[0]) + (self.alpha * inputs[1])\n",
        "    return output\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ykDProxZfWK"
      },
      "source": [
        "# minibatch stev\n",
        "class Minibatchstev(Layer):\n",
        "  # init this layer\n",
        "  def __init__(self,**kwargs):\n",
        "    super(Minibatchstev,self).__init__(**kwags)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    # calculate the mean value cross the batch \n",
        "    mean_3d = backend.mean(inputs, axis = 0,keepdims = True)\n",
        "    # calculate squared different (variance) between pixel value (inputs and mean)\n",
        "    squared_diff = backend.square(input - mean)\n",
        "    # calculate mean of variance\n",
        "    mean_squared_diff = backend.mean(squared_diff,axis = 0,keepdims = True)\n",
        "    # add a small value to avoid a blow-up when we calculate stdev (ensure the mean is not zero)\n",
        "    mean_squared_diff += 1e-8\n",
        "    # sqrt of the variance\n",
        "    stdev = backend.sqrt(mean_squared_diff)\n",
        "    # calculate the mean stdev across each pixel\n",
        "    mean_pix = backend.mean(stdev,keepdims = True)\n",
        "    shape = backend.shape(inputs)\n",
        "    output = backend.tile(mean_pix,(shape[0], shape[1], shape[2], 1))\n",
        "    # concat output with mean_\n",
        "    combined = backend.concatenate([inputs, output], axis=-1)\n",
        "    return combined\n",
        "  \n",
        "  def caculate_output_shape(self,input_shape):\n",
        "    input_shape = list(input_shape)\n",
        "    input_shape[-1]+=1\n",
        "    return tuple(input_shape)\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5b4KsfKqSAZ"
      },
      "source": [
        "# pixelNormalization\n",
        "\n",
        "class PixelNormalization(Layer):\n",
        "  #initalize the layer\n",
        "  def __init__(self,**kwargs):\n",
        "    super(PixelNormalization,self).__init__(**kwargs)\n",
        "\n",
        "  # calculate pixelnormal\n",
        "  def call(self,inputs):\n",
        "    # calculate square pixel values\n",
        "    values = inputs**2\n",
        "    # calculate the mean pixel values\n",
        "    mean_values = backend.mean(values, axis = -1 ,keepdims = True)\n",
        "    # ensure the mean is not zero\n",
        "    mean_values += 1.0e-8\n",
        "    # calculate the sqrt of the mean squared value (L2 norm)\n",
        "    l2 = backend.sqrt(mean_values)\n",
        "\t\t# normalize values by the l2 norm\n",
        "    normalized = inputs / l2\n",
        "    return normalized\n",
        "\n",
        "  # define the putput shape of the layer\n",
        "  def compute_output_shape(self,input_shape):\n",
        "    return input_shape"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWMSTTr8sX1W"
      },
      "source": [
        "#calculate wloss\n",
        "def wassertein_loss(ytrue,ypred):\n",
        "  return backend.mean(ytrue*ypred)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuzW35TAwyYZ"
      },
      "source": [
        "# grow D block\n",
        "def add_D_block(old_model,n_input_layer = 3):\n",
        "  \"\"\" \n",
        "  this function return 2 version:\n",
        "  1.model without newblock\n",
        "  2.model with newblock (use fadedblock)\n",
        "  \"\"\"\n",
        "  #init weight\n",
        "  init = RandomNormal(stddev = 0.02)\n",
        "  # store shape of model\n",
        "  shape_model = list(old_model.input.shape)\n",
        "  # new size of input (double)\n",
        "  input_shape = (shape_model[-2]*2,shape_model[-2]*2,shape_model[-1])\n",
        "  in_image = Input(shape = input_shape)\n",
        "\n",
        "  # from RGB block\n",
        "\n",
        "  d = Conv2D(128,(1,1),padding = 'same',kernel_initializer= init,kernel_constraint = max_norm(1))(in_image)\n",
        "  d = LeakyReLU(alpha = 0.2)(d)\n",
        "  \n",
        "  # new block\n",
        "  d = Conv2D(128,(3,3),padding = 'same',kernel_initializer = init,kernel_constraint=max_norm(1.0))(d)\n",
        "  d = LeakyReLU(alpha = 0.2)(d)\n",
        "  d = Conv2D(128,(3,3),padding = 'same',kernel_initializer = init,kernel_constraint=max_norm(1.0))(d)\n",
        "  d = LeakyReLU(alpha = 0.2)(d)\n",
        "  d = AveragePooling2D()(d)\n",
        "\n",
        "  new_block = d\n",
        "\n",
        "  # skip input layer,conv(1,1) and activation so start with n_input_layer = 3\n",
        "  for i in range(n_input_layer,len(old_model.layers)):\n",
        "    d = old_model.layers[i](d)\n",
        "  # model without newblock\n",
        "  model1 = Model(in_image,d)\n",
        "  # compile mode1\n",
        "  model1.compile(loss = wassertein_loss, optimizer = Adam(learning_rate = 0.001,beta_1=0,beta_2=0.99,epsilon=10e-8))\n",
        "    \n",
        "  # downsample the new larger image\n",
        "  downsample = AveragePooling2D()(in_image)\n",
        "  # connect old input to downsampled new input\n",
        "\n",
        "  # downsample througt the 1x1 conv\n",
        "  old_block = old_model.layers[1](downsample)\n",
        "  # thought the activation\n",
        "  old_block = old_model.layers[2](old_block)\n",
        "\n",
        "  # fade use FadeBlock\n",
        "  d = FadeBlock()([old_block,new_block])\n",
        "\n",
        "  # skip input layer,conv(1,1) and activation so start with n_input_layer = 3\n",
        "  for i in range(n_input_layer,len(old_model.layers)):\n",
        "    d = old_model.layers[i](d)\n",
        "  # model without newblock\n",
        "  model2 = Model(in_image,d)\n",
        "  # compile mode2\n",
        "  model2.compile(loss = wassertein_loss, optimizer = Adam(learning_rate = 0.001,beta_1=0,beta_2=0.99,epsilon=10e-8))\n",
        "  return [model1,model2]\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AE66-tYsFzsb"
      },
      "source": [
        "def discriminator(blocks,input_shape = (4,4,3)):\n",
        "  init = RandomNormal(stddev=0.02)\n",
        "  model_list = list()\n",
        "  in_image = Input(shape = input_shape)\n",
        "\n",
        "  #conv 1x1\n",
        "  d = Conv2D(128,(1,1),padding='same',kernel_initializer='he_normal')(in_image)\n",
        "  d = LeakyReLU(alpha=0.2)(d)\n",
        "  #conv 3x3\n",
        "  d = Conv2D(128,(3,3),padding='same',kernel_initializer='he_normal')(d)\n",
        "  d = BatchNormalization()(d)\n",
        "  d = LeakyReLU(alpha=0.2)(d)\n",
        "  #conv 4x4\n",
        "  d = Conv2D(128,(4,4),padding ='same',kernel_initializer='he_normal')(d)\n",
        "  d = BatchNormalization()(d)\n",
        "  d = LeakyReLU(alpha=0.2)(d)\n",
        "\n",
        "  #dense output\n",
        "  d = Flatten()(d)\n",
        "  out_class = Dense(1)(d)\n",
        "\n",
        "  # define mode\n",
        "  model = Model(in_image,out_class)\n",
        "  # compile mode\n",
        "  model.compile(loss = 'mse',optimizer = Adam(learning_rate=0.001,beta_1=0,beta_2=0.99,epsilon= 10e-8))\n",
        "  # store model\n",
        "  model_list.append([model,model])\n",
        "\n",
        "\n",
        "\n",
        "  for i in range(1,blocks):\n",
        "    #old_model = model_list[i-1][0]\n",
        "    models = add_D_block(model_list[i-1][0])\n",
        "    model_list.append(models)\n",
        "  return model_list"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKIiGxAWNtO7"
      },
      "source": [
        "# grow G\n",
        "def add_G_block(old_model):\n",
        "  # init weight\n",
        "  init = RandomNormal(stddev = 0.02)\n",
        "  # get the output of the last block\n",
        "  block_end = old_model.layers[-2].output\n",
        "  # upsample the output of the last block\n",
        "  upsampling = UpSampling2D()(block_end)\n",
        "\n",
        "  #define\n",
        "  g = Conv2D(128,(3,3),padding='same',kernel_regularizer=init,kernel_constraint=max_norm(1))(upsampling)\n",
        "  g = PixelNormalization()(g)\n",
        "  g = LeakyReLU(alpha=0.2)(g)\n",
        "  g = Conv2D(128,(3,3),padding='same',kernel_initializer=init,kernel_constraint=max_norm(1))(g)\n",
        "  g = PixelNormalization()(g)\n",
        "  g = LeakyReLU(alpha=0.2)(g)\n",
        "  # new layer ouput \n",
        "  out_image = Conv2D(3,(1,1),padding='same',kernel_initializer=init,kernel_constraint=max_norm(1))(g)\n",
        "  model1=Model(old_model.input,out_image)\n",
        "\n",
        "  \n",
        "  out_image2 = Conv2D(3,(1,1),padding='same',kernel_initializer=init,kernel_constraint=max_norm(1))(upsampling)\n",
        "  merged = FadeBlock()([out_image2,out_image])\n",
        "  model2 = Model(old_model.input,merged)\n",
        "  return [model1,model2]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQM2KumZXVAw"
      },
      "source": [
        "def generator(latent_dim,blocks,in_dim = 4):\n",
        "  \"\"\"\n",
        "  in this function G isnt compile\n",
        "  G is trained via the D using W loss\n",
        "  \"\"\"\n",
        "  # init weigjt\n",
        "  init = RandomNormal(stddev=0.2)\n",
        "  # make list to store\n",
        "  model_list = list ()\n",
        "  #input\n",
        "  input = Input(shape=(latent_dim,))\n",
        "\n",
        "  g = Dense(128 * in_dim * in_dim,kernel_initializer=init,kernel_constraint=max_norm(1))(input)\n",
        "  g = Reshape((in_dim,in_dim,128))(g)\n",
        "  # conv 4x4\n",
        "  g = Conv2D(128,(3,3),padding='same',kernel_initializer=init,kernel_constraint=max_norm(1.0))(g)\n",
        "  g = PixelNormalization()(g)\n",
        "  g = LeakyReLU(alpha=0.2)(g)\n",
        "  # conv 3x3\n",
        "  g = Conv2D(128,(3,3),padding='same',kernel_initializer=init,kernel_constraint=max_norm(1.0))(g)\n",
        "  g = PixelNormalization()(g)\n",
        "  g = LeakyReLU(alpha=0.2)(g)\n",
        "  # conv 1x1 ,output block (from RGB)\n",
        "  out_img = Conv2D(3,(1,1),padding='same',kernel_initializer=init,kernel_constraint=max_norm(1))(g)\n",
        "  # define model\n",
        "  model = Model(input,out_img)\n",
        "  # store\n",
        "  model_list.append([model,model])\n",
        "  for i in range(1,blocks):\n",
        "    old_model = model_list[i-1][0]\n",
        "    #creat new model for new resolution\n",
        "    models = add_G_block(old_model)\n",
        "    #store\n",
        "    model_list.append(models)\n",
        "  return model_list"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybCEmxqVaq1a"
      },
      "source": [
        "def Composite(D_model,G_model):\n",
        "  model_list = list()\n",
        "  for i in range(len(D_model)):\n",
        "    g_model,d_model = G_model[i],D_model[i]\n",
        "    # non fade in model\n",
        "    d_model[0].trainable = False\n",
        "    model1 = Sequential()\n",
        "    model1.add(g_model[0])\n",
        "    model1.add(d_model[0])\n",
        "    model1.compile(loss = wassertein_loss,optimizer = Adam(learning_rate=0.001,beta_1=0,beta_2=0.99,epsilon=1e-07))\n",
        "    # fade in model\n",
        "    model2 = Sequential()\n",
        "    model2.add(g_model[0])\n",
        "    model2.add(d_model[0])\n",
        "    model2.compile(loss = wassertein_loss,optimizer = Adam(learning_rate=0.001,beta_1=0,beta_2=0.99,epsilon=1e-07))\n",
        "    #store\n",
        "    model_list.append([model1,model2])\n",
        "  return model_list"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yiow69-dfKma"
      },
      "source": [
        "def load_data_image(img_path):\n",
        "  X = []\n",
        "  files = glob.glob(os.path.join(img_path, '*.jpg'))\n",
        "  for file in files:\n",
        "    img = cv2.imread(file)\n",
        "    img = cv2.resize(img,(128,128))\n",
        "    X.append(img)\n",
        "  X = [np.random.random((128,128,3)) for i in range(len(X))]\n",
        "  X = np.concatenate([arr[np.newaxis] for arr in X])\n",
        "  X = X.astype('float32')\n",
        "  X = (X - 127.5)/127.5\n",
        "  return X"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49DcHMaT7p2_"
      },
      "source": [
        "def scale_dataset(dataset, new_shape):\n",
        "\timages_list = list()\n",
        "\tfor image in dataset:\n",
        "\t\t# resize with nearest neighbor interpolation\n",
        "\t\tnew_image = resize(image, new_shape, 0)\n",
        "\t\t# store\n",
        "\t\timages_list.append(new_image)\n",
        "\treturn asarray(images_list)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsZHutNvhJkS"
      },
      "source": [
        "def select_real_sample(dataset,n_sample):\n",
        "  # choose random sample\n",
        "  indx = randint(0,dataset.shape[0],n_sample)\n",
        "  x = dataset[indx]\n",
        "  # generate label\n",
        "  y = ones((n_sample,1))\n",
        "  return x,y"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btfNMzmHtco2"
      },
      "source": [
        "def generate_x_input(latent_dim, n_sample):\n",
        "  # random input \n",
        "  x_input = randn(latent_dim*n_sample)\n",
        "  # reshape into a batch of inputs for network\n",
        "  x_input = x_input.reshape(n_sample,latent_dim)\n",
        "  return x_input"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-13MytCEwO8r"
      },
      "source": [
        "def generate_fake_img(generator,latent_dim,n_samples):\n",
        "  # generate a noise\n",
        "  x_input = generate_x_input(latent_dim,n_sample)\n",
        "  # generate\n",
        "  x  = generator.predict(x_input)\n",
        "  # lable for fake img\n",
        "  y = -ones((n_samples,1))\n",
        "  return x,y"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwExgTrsxQT6"
      },
      "source": [
        "def update_alpha_fadeblock(models, step,n_steps):\n",
        "  alpha = step/float(n_steps-1)\n",
        "  #update alpha\n",
        "  for model in models:\n",
        "    for layer in model.layers:\n",
        "      if(isinstance(layer,FadeBlock)):\n",
        "        backend.set_value(layer.alpha,alpha)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWdQxIMp1t7O"
      },
      "source": [
        "def summarize_performance(status, g_model, latent_dim, n_samples=25):\n",
        "\t# devise name\n",
        "\tgen_shape = g_model.output_shape\n",
        "\tname = '%03dx%03d-%s' % (gen_shape[1], gen_shape[2], status)\n",
        "\t# generate images\n",
        "\tX, _ = generate_fake_img(g_model, latent_dim, n_samples)\n",
        "\t# normalize pixel values to the range [0,1]\n",
        "\tX = (X - X.min()) / (X.max() - X.min())\n",
        "\t# plot real images\n",
        "\tsquare = int(sqrt(n_samples))\n",
        "\tfor i in range(n_samples):\n",
        "\t\tpyplot.subplot(square, square, 1 + i)\n",
        "\t\tpyplot.axis('off')\n",
        "\t\tpyplot.imshow(X[i])\n",
        "\t# save plot to file\n",
        "\tfilename1 = 'plot_%s.png' % (name)\n",
        "\tpyplot.savefig(filename1)\n",
        "\tpyplot.close()\n",
        "\t# save the generator model\n",
        "\tfilename2 = 'model_%s.h5' % (name)\n",
        "\tg_model.save(filename2)\n",
        "\tprint('>Saved: %s and %s' % (filename1, filename2))"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbN0qxb1zVVl"
      },
      "source": [
        "def train_epochs(g_model,d_model,gan_model,dataset,n_epochs,n_batchs,fadein = False):\n",
        "  # the number of batchs per training epoch\n",
        "  batchs_per_epoch = int (dataset.shape[0]/n_batchs)\n",
        "  # the number of training iterations\n",
        "  n_steps = batchs_per_epoch * n_epochs\n",
        "  for i in range(n_steps):\n",
        "    if fadein:\n",
        "      # update alpha for all fadeblock layer when fading in\n",
        "      update_alpha_fadeblock([g_model,d_model,gan_model],i,n_steps)\n",
        "    # creat real and fake data\n",
        "    X_real, y_real = generate_x_input(dataset,int(n_batchs/2))\n",
        "    X_fake, y_fake = generate_fake_img(g_model,latent_dim,int(n_batchs/2))\n",
        "    # update discriminator\n",
        "    d_loss1 = d_model.train_on_batch(X_real,y_real)\n",
        "    d_loss2 = d_model.train_on_batch(X_fake,y_fake)\n",
        "    # update the generator via the discriminator' error\n",
        "    z_input = generate_latent_points(latent_dim, n_batch)\n",
        "    y_real2 = ones((n_batch, 1))\n",
        "    g_loss = gan_model.train_on_batch(z_input, y_real2)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4C25-_dR2rmp"
      },
      "source": [
        "def train(g_models,d_models,gan_models,dataset,lantent_dim,e_norm, e_fadein , n_batch):\n",
        "  # fit the first model in list models\n",
        "  g_model, d_model, gan_model = g_models[0][0], d_models[0][0], gan_models[0][0]\n",
        "  # get output shape\n",
        "  gen_shape = g_model.output_shape\n",
        "  scale_data = scale_dataset(dataset,gen_shape[1:])\n",
        "  \n",
        "  train_epochs(g_model,d_model,gan_model,dataset,e_norm[0],n_batchs[0])\n",
        "\n",
        "  for i in range(1,len(g_models)):\n",
        "    [g_model,g_fade] = g_models[i]\n",
        "    [d_model, d_fade] = d_models[i]\n",
        "    [gan_model, gan_fade] = gan_models[i]\n",
        "    gen_shape = g_model.output_shape\n",
        "\n",
        "    scaled_data = scale_dataset(dataset, gen_shape[1:])\n",
        "    train_epochs(g_fade,d_fade,gan_fade,dataset,e_fade[i],n_batch[i],True)\n",
        "    summarize_performance('faded', g_fade, latent_dim)\n",
        "    train_epochs(g_model, d_model, gan_model, scaled_data, e_norm[i], n_batch[i])\n",
        "    summarize_performance('tuned', g_model, latent_dim)\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ItZtz6x56Mu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "fbcb512a-cdf6-400f-dff8-48274c8db57e"
      },
      "source": [
        "img_path = '/content/drive/My Drive/data/data/augmented data/yes'\n",
        "n_blocks = 6\n",
        "latent_dim = 100\n",
        "d_models = discriminator(n_blocks)\n",
        "g_models = generator(latent_dim,n_blocks)\n",
        "gan_models = Composite(d_models,g_models)\n",
        "dataset = load_data_image(img_path)\n",
        "n_batch = [16, 16, 16, 8, 4, 4]\n",
        "n_epochs = [5, 8, 8, 10, 10, 10]\n",
        "train(g_models,d_models,gan_models,dataset,latent_dim,n_epoch,n_epochs,n_batch)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-e172457c8e52>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mn_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_models\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md_models\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgan_models\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: train() missing 1 required positional argument: 'n_batch'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XhmQsI-27qR"
      },
      "source": [
        "#model = tf.keras.models.load_model('model.h5')\n",
        "#latent_dim=100\n",
        "#n_images = 10\n",
        "#input = generate_x_input(latent_dim,n_images)\n",
        "#X = model.predict(input)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}